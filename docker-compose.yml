services:
  # Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - kafka-assignment-network
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log

  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    networks:
      - kafka-assignment-network
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  # Kibana
  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - kafka-assignment-network

  # Kafka Connect
  kafka-connect:
    build:
      context: .
      dockerfile: kafka-connect/Dockerfile
    container_name: kafka-connect
    depends_on:
      - kafka1
      - kafka2
      - mysql
      - elasticsearch
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 2
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 2
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 2
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_LOG4J_ROOT_LOGLEVEL: WARN
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components
    networks:
      - kafka-assignment-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/connectors"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Kafka Broker 1
  kafka1:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka1
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
    networks:
      - kafka-assignment-network
    volumes:
      - kafka1_data:/var/lib/kafka/data

  # Kafka Broker 2
  kafka2:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka2
    depends_on:
      - zookeeper
    ports:
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:29093,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29093,PLAINTEXT_HOST://0.0.0.0:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
    networks:
      - kafka-assignment-network
    volumes:
      - kafka2_data:/var/lib/kafka/data

  # MySQL Database
  mysql:
    image: mysql:8.0
    container_name: mysql
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: shopstream
      MYSQL_USER: shopuser
      MYSQL_PASSWORD: shoppassword
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
      - ./init-mysql.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - kafka-assignment-network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Order Producer
  order-producer:
    build: 
      context: .
      dockerfile: order-producer/Dockerfile
    container_name: order-producer
    depends_on:
      - kafka1
      - kafka2
    ports:
      - "8081:8081"
    environment:
      SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093
    networks:
      - kafka-assignment-network

  # Order Consumer
  order-consumer:
    build:
      context: .
      dockerfile: order-consumer/Dockerfile
    container_name: order-consumer
    depends_on:
      - kafka1
      - kafka2
      - mysql
    ports:
      - "8082:8082"
    environment:
      SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093
      SPRING_DATASOURCE_URL: jdbc:mysql://mysql:3306/shopstream
      SPRING_DATASOURCE_USERNAME: shopuser
      SPRING_DATASOURCE_PASSWORD: shoppassword
    networks:
      - kafka-assignment-network

  # Kafka Streams
  kafka-streams:
    build:
      context: .
      dockerfile: kafka-streams/Dockerfile
    container_name: kafka-streams-app
    depends_on:
      - kafka1
      - kafka2
    ports:
      - "8084:8084"
    environment:
      SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka1:29092,kafka2:29093
    networks:
      - kafka-assignment-network

networks:
  kafka-assignment-network:
    driver: bridge

volumes:
  zookeeper_data:
  zookeeper_logs:
  kafka1_data:
  kafka2_data:
  mysql_data:
  elasticsearch_data: